════════════════════════════════════════════════════════════════════════════════
DATA THOUGHT ENGINE: ARCHITECTURE & REASONING FLOW
v1.1.0-cross-run-reasoning
════════════════════════════════════════════════════════════════════════════════

1. SYSTEM OVERVIEW

  Input CSV          →  Analysis Engine  →  JSON Reasoning Trace + Narrative
  (Tabular Data)        (Six Layers)      (Audit Trail + Explanation)


2. LAYERED ARCHITECTURE

The system is organized into six sequential reasoning layers plus supporting
infrastructure (context management, logging, utilities):

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 1: INGESTION                                                      ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Read CSV, infer schema, stream rows                      ┃
┃ Input:         File path (string)                                        ┃
┃ Output:        Row generator + inferred schema + Context                 ┃
┃ Key Files:     loader.py, schema.py, stream.py                          ┃
┃                                                                          ┃
┃ Details:                                                                 ┃
┃   • Validates file exists and has .csv extension                        ┃
┃   • Reads first 200 rows deterministically to infer types                ┃
┃   • Type detection: int, float, datetime, bool, str, null               ┃
┃   • Returns row generator (lazy; full file never loaded)                 ┃
┃   • Creates immutable Context (dataset path, schema, timestamps)         ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                  ↓
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 2: OBSERVATION                                                    ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Detect anomalies and patterns in data                    ┃
┃ Input:         Row generator + Context                                   ┃
┃ Output:        List of Signal objects                                    ┃
┃ Key Files:     detectors.py, signals.py, metrics.py                     ┃
┃                                                                          ┃
┃ Detectors (all deterministic, no randomness):                            ┃
┃                                                                          ┃
┃   1. Variance Spike Detector                                             ┃
┃      • For each numeric column, compute score = variance / (mean²)       ┃
┃      • Threshold: if score > 4, generate Signal                          ┃
┃      • Interpretation: Values are highly scattered                       ┃
┃                                                                          ┃
┃   2. Monotonic Break Detector                                            ┃
┃      • For each numeric column, count direction changes                  ┃
┃      • Example: [100, 102, 99] has 1 change (up → down)                 ┃
┃      • Threshold: if changes ≥ 1, generate Signal                        ┃
┃      • Interpretation: Trend reversed                                    ┃
┃                                                                          ┃
┃   3. Distribution Shift Detector                                         ┃
┃      • For each column, compute Shannon entropy: H = -Σ(p_i*log₂(p_i))  ┃
┃      • Threshold: if H < 0.5 or H > 4, generate Signal                  ┃
┃      • Interpretation: Distribution unusually uniform or chaotic         ┃
┃                                                                          ┃
┃ Output: List of Signal(kind, column, score, details) objects            ┃
┃ Note:   Operates on up to 1000 rows; memory-efficient                   ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                  ↓
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 3: HYPOTHESIS GENERATION                                          ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Generate competing explanations for each signal          ┃
┃ Input:         List of Signal objects                                    ┃
┃ Output:        List of Hypothesis objects                                ┃
┃ Key Files:     generator.py, hypothesis.py, validator.py                ┃
┃                                                                          ┃
┃ Generation Rules (deterministic, rule-based):                            ┃
┃                                                                          ┃
┃   Variance Spike Signal → 2 Hypotheses:                                  ┃
┃     H1: "Pricing or discount changes caused variance"                    ┃
┃         Assumptions: [discount_column_exists, changes_tracked]           ┃
┃         Expectations: {score: signal_score * 0.6}                        ┃
┃     H2: "External demand or supply shock caused variance"                ┃
┃         Assumptions: [market_conditions_affect_outcomes]                 ┃
┃         Expectations: {score: signal_score * 0.7}                        ┃
┃                                                                          ┃
┃   Monotonic Break Signal → 2 Hypotheses:                                 ┃
┃     H1: "Gradual process degradation"                                    ┃
┃         Expectations: {score: 1.5, mechanism: degradation}               ┃
┃     H2: "Sudden operational regime shift"                                ┃
┃         Expectations: {score: 1.6, mechanism: regime_shift}              ┃
┃                                                                          ┃
┃   Distribution Shift Signal → 2 Hypotheses:                              ┃
┃     H1: "Measurement or collection method changed"                       ┃
┃         Expectations: {score: 0.8}                                       ┃
┃     H2: "Real underlying process shifted"                                ┃
┃         Expectations: {score: 1.2}                                       ┃
┃                                                                          ┃
┃ Validator:                                                               ┃
┃   • Removes exact duplicates (by ID)                                     ┃
┃   • Detects and removes circular logic (A assumes B, B assumes A)        ┃
┃   • Returns deduplicated, logically consistent list                      ┃
┃                                                                          ┃
┃ IDs: Deterministic content-hashes (SHA-1) of hypothesis statement       ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                  ↓
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 4: REASONING & EVALUATION                                         ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Test and rank hypotheses                                 ┃
┃ Input:         List of Hypothesis objects                                ┃
┃ Output:        List of Node objects (test results)                       ┃
┃ Key Files:     evaluator.py, node.py, graph.py                          ┃
┃                                                                          ┃
┃ Evaluation Test (simple, deterministic rule):                            ┃
┃                                                                          ┃
┃   For each hypothesis:                                                   ┃
┃     IF hypothesis.expectations.score ≥ 1.0                              ┃
┃       result = "supported"                                               ┃
┃     ELSIF hypothesis.expectations.score > 0                              ┃
┃       result = "weak_support"                                            ┃
┃     ELSE                                                                  ┃
┃       result = "unsupported"                                             ┃
┃                                                                          ┃
┃ Node Creation:                                                           ┃
┃   Create Node(hypothesis_id, test="expectation_score_test",             ┃
┃              result, score) for each evaluation                          ┃
┃                                                                          ┃
┃ Graph Construction:                                                      ┃
┃   • Add all nodes to directed acyclic graph (DAG)                        ┃
┃   • Ensure no cycles (prevents circular reasoning)                       ┃
┃   • Topological ordering guarantees consistent evaluation order          ┃
┃                                                                          ┃
┃ Summary Calculation:                                                     ┃
┃   {supported: count, weak_support: count, unsupported: count}            ┃
┃                                                                          ┃
┃ Dominant Hypothesis:                                                     ┃
┃   hypothesis with max(score) across all nodes                            ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                  ↓
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 5: HISTORICAL COMPARISON (v1.1)                                   ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Compare current reasoning to prior runs                  ┃
┃ Input:         Current Node results + reasoning nodes                    ┃
┃ Output:        Comparison result {status, message}                       ┃
┃ Key Files:     history.py                                                ┃
┃                                                                          ┃
┃ Reasoning Signature Computation:                                         ┃
┃   signature = {                                                          ┃
┃     dataset_hash: SHA-256[CSV_file][:16],          [deterministic ID]   ┃
┃     supported_ids: sorted([h_id | result=supported]),                    ┃
┃     rejected_ids: sorted([h_id | result=unsupported]),                   ┃
┃     weak_ids: sorted([h_id | result=weak_support]),                      ┃
┃     dominant_hypothesis: h_id with max(score),                           ┃
┃     dominant_score: float                                                ┃
┃   }                                                                       ┃
┃                                                                          ┃
┃ Historical Comparison:                                                   ┃
┃   1. Load all prior runs from dte_runs/ directory                        ┃
┃   2. Reconstruct signatures from stored JSON                             ┃
┃   3. Compare current signature to most recent prior run                  ┃
┃   4. Return comparison status                                            ┃
┃                                                                          ┃
┃ Comparison Outcomes:                                                     ┃
┃   exact_match           → Identical reasoning; reproducible              ┃
┃   dominant_changed      → Different dominant; contradiction              ┃
┃   partial_reinforcement → Some overlap; partially stable                 ┃
┃   reasoning_diverged    → Completely different conclusions               ┃
┃   different_dataset     → CSV changed; comparison invalid                ┃
┃   no_prior_runs         → First run; no baseline                         ┃
┃                                                                          ┃
┃ Output: {status: str, message: str, [additional_fields]}                 ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                  ↓
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 6: EXPLANATION & NARRATIVE                                        ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Compose human-readable explanation                       ┃
┃ Input:         Node results + historical comparison                      ┃
┃ Output:        Narrative string (composed, not templated)                ┃
┃ Key Files:     narrative.py, formatter.py                                ┃
┃                                                                          ┃
┃ Narrative Composition:                                                   ┃
┃                                                                          ┃
┃   1. For each Node in evaluation results:                                ┃
┃      Generate a phrase based on (result, score)                          ┃
┃      Examples:                                                           ┃
┃        "This finds strong support..." (if result == "supported")         ┃
┃        "There is limited support..." (if result == "weak_support")       ┃
┃        "Findings do not support..." (if result == "unsupported")         ┃
┃                                                                          ┃
┃   2. Add summary line:                                                   ┃
┃      "Summary: 6 supported; 2 weak_support; 0 unsupported."             ┃
┃                                                                          ┃
┃   3. Append historical consistency section (v1.1):                       ┃
┃      Based on comparison result:                                         ┃
┃        exact_match → "This reasoning is identical to the prior run..."  ┃
┃        dominant_changed → "The dominant explanation has shifted from..  ┃
┃        etc.                                                              ┃
┃                                                                          ┃
┃   4. Join all sentences into single narrative string                     ┃
┃                                                                          ┃
┃ Result:                                                                  ┃
┃   "There is limited support the hypothesis... This finds strong support  ┃
┃    the hypothesis... Summary: 6 supported; 2 weak_support; 0 unsupp...  ┃
┃    Historical Context: This reasoning is identical to the prior run..."  ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                  ↓
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ LAYER 7: PERSISTENCE & AUDIT TRAIL                                      ┃
┃─────────────────────────────────────────────────────────────────────────┃
┃ Responsibility: Save reasoning to JSON for audit and replay              ┃
┃ Input:         Results, narrative, context                              ┃
┃ Output:        JSON file in dte_runs/ directory                          ┃
┃ Key Files:     store.py                                                  ┃
┃                                                                          ┃
┃ Filename:                                                                ┃
┃   run_YYYY-MM-DDTHH-MM-SS.SSSSSS.json                                    ┃
┃   Example: run_2026-01-03T05-56-06.887230.json                           ┃
┃                                                                          ┃
┃ File Structure:                                                          ┃
┃   {                                                                      ┃
┃     "start_time": "2026-01-03T05:56:06.887230",                          ┃
┃     "dataset_path": "data_thought_engine/data/sample.csv",              ┃
┃     "results": {                                                         ┃
┃       "summary": {                                                       ┃
┃         "supported": 6,                                                  ┃
┃         "weak_support": 2,                                               ┃
┃         "unsupported": 0                                                 ┃
┃       },                                                                  ┃
┃       "nodes": [                                                         ┃
┃         {                                                                ┃
┃           "id": "hash",                                                  ┃
┃           "hypothesis_id": "hash",                                       ┃
┃           "test": "expectation_score_test",                              ┃
┃           "result": "supported",                                         ┃
┃           "score": 1.2,                                                  ┃
┃           "details": { "expectations": {...} }                           ┃
┃         },                                                               ┃
┃         ...                                                              ┃
┃       ]                                                                   ┃
┃     },                                                                    ┃
┃     "narrative": "[complete narrative string]"                           ┃
┃   }                                                                       ┃
┃                                                                          ┃
┃ Uses:                                                                    ┃
┃   • Audit trail: Regulators can inspect any run independently            ┃
┃   • Replay: Prior reasoning can be inspected without re-running          ┃
┃   • Comparison: Future runs compare against this JSON                    ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛


3. COMPLETE DATA FLOW EXAMPLE

CSV Input:
  date,region,revenue,discount,delivery_days
  2025-12-01,North,105,5,2
  2025-12-02,North,102,5,2
  ...
  2025-12-20,North,10000,50,20      ← Big variance spike!
  ...

Step 1: INGESTION
  Output: rows=[...], schema={date:datetime, region:str, revenue:int, ...}

Step 2: OBSERVATION
  Variance spike detector on "revenue":
    variance = 1234567, mean = 500
    score = 1234567 / (500²) = 4.94 > threshold 4
    → Signal(kind="variance_spike", column="revenue", score=4.94)
  
  Monotonic break detector on "delivery_days":
    sequence = [2, 2, 3, ..., 20, 21, 22, 2, 1, 0]
    direction changes = 2 ≥ 1
    → Signal(kind="monotonic_break", column="delivery_days", score=2.0)

Step 3: HYPOTHESIS GENERATION
  For variance_spike signal on "revenue":
    H1: "Variance explained by pricing changes"
        score = 4.94 * 0.6 = 2.96
    H2: "Variance explained by external shock"
        score = 4.94 * 0.7 = 3.46
  
  For monotonic_break signal on "delivery_days":
    H3: "Gradual degradation"
        score = 1.5
    H4: "Regime shift"
        score = 1.6

Step 4: REASONING
  Test each hypothesis:
    H1: 2.96 ≥ 1.0 → "supported"
    H2: 3.46 ≥ 1.0 → "supported"
    H3: 1.5 ≥ 1.0 → "supported"
    H4: 1.6 ≥ 1.0 → "supported"
  
  Summary: {supported: 4, weak_support: 0, unsupported: 0}
  Dominant: H2 (score 3.46)

Step 5: HISTORICAL COMPARISON
  Current signature:
    dataset_hash = "a3f9e2b7c4d1f8e3"
    supported_ids = [H1, H2, H3, H4]
    dominant = H2 (score 3.46)
  
  Prior run signature (if exists):
    dataset_hash = "a3f9e2b7c4d1f8e3"
    supported_ids = [H1, H2, H3, H4]
    dominant = H2 (score 3.46)
  
  Comparison: "exact_match"

Step 6: NARRATIVE
  "This finds strong support the hypothesis through expectation score test
   (score=2.96) This finds strong support the hypothesis through expectation
   score test (score=3.46) This finds strong support the hypothesis through
   expectation score test (score=1.50) This finds strong support the hypothesis
   through expectation score test (score=1.60) Summary: 4 supported; 0
   weak_support; 0 unsupported. Historical Context: This reasoning is identical
   to the prior run on the same dataset, indicating consistent and reproducible
   analysis."

Step 7: PERSISTENCE
  Saved to: dte_runs/run_2026-01-03T05-56-06.887230.json
  (Contains all above data as JSON)


4. SUPPORTING INFRASTRUCTURE

Context Management (core/context.py)
  • Immutable Context dataclass
  • Holds: dataset_path, schema, start_time, metadata
  • Passed explicitly through pipeline (no globals)

Engine Orchestration (core/engine.py)
  • Calls layers in order: ingest → observe → hypothesis → reason → 
    explain → persist
  • No business logic; pure orchestration
  • Computes reasoning signature and historical comparison

Lifecycle Management (core/lifecycle.py)
  • Validates pipeline stage order
  • Prevents invalid execution sequences
  • Ensures frozen architecture compliance

Utilities (utils/)
  • stats.py: Mean, variance, median, entropy (deterministic implementations)
  • checks.py: Assertions and validation
  • logger.py: Structured JSON logging

CLI Interface (cli/think.py)
  • Accepts dataset path as argument
  • Validates input
  • Triggers engine


5. DESIGN PRINCIPLES THROUGHOUT

Immutability
  • All major objects are frozen dataclasses
  • No mutation; transformations are pure functions
  • Enables safe concurrent inspection

Determinism
  • All IDs are content-hashes (SHA-1, SHA-256)
  • Sorted ordering everywhere
  • No randomness at any layer
  • Numerically stable algorithms

Modularity
  • Each layer has clear, single responsibility
  • Layers depend only on outputs of previous layer
  • Easy to inspect, test, and modify independently

Explicitness
  • Context passed explicitly (no implicit globals)
  • Each hypothesis lists assumptions
  • Each node records test and result
  • No hidden behavior or implicit state

Auditability
  • Complete JSON persistence
  • Reasoning traces are immutable
  • Historical comparison enables review
  • All decisions are traceable


6. EXECUTION TIME COMPLEXITY

Ingestion:        O(n) — reads first 200 rows deterministically
Observation:      O(n) — scans columns (up to 1000 rows)
Hypothesis Gen:   O(s) — for each signal, generate 2 hypotheses (s = signal count)
Reasoning:        O(h) — test each hypothesis (h = hypothesis count)
Historical Comp:  O(r) — compare against prior runs (r = run count)
Persistence:      O(h) — write nodes to JSON

Total: O(n + h + r) — linear in data rows and hypothesis count


7. MEMORY USAGE

Row streaming:    O(1) — rows consumed and discarded (no accumulation)
Column buffers:   O(1000) — max 1000 rows per column
Signals list:     O(s) — small (typically 3-5 signals)
Hypotheses:       O(h) — typically 6-10
Nodes:            O(h) — one per hypothesis
JSON in memory:   O(h) — small structure for persistence

Total: O(1000 + h) — memory-efficient even for large datasets

════════════════════════════════════════════════════════════════════════════════
